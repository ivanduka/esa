{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda30fb8a07f75f4a94a3c6b568e65d1132",
   "language": "python",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "from sqlalchemy import text, create_engine\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pdf_files_folder = Path(\"//luxor/data/branch/Environmental Baseline Data\\Version 4 - Final/PDF\")\n",
    "csv_tables_folder = Path(\"//luxor/data/branch/Environmental Baseline Data\\Version 4 - Final/all_csvs\")\n",
    "\n",
    "if not pdf_files_folder.exists():\n",
    "    print(pdf_files_folder, \"does not exist!\")\n",
    "elif not csv_tables_folder.exists():\n",
    "    print(csv_tables_folder, \"does not exist!\")\n",
    "else:\n",
    "    print(\"All paths are accessible.\")\n",
    "\n",
    "\n",
    "load_dotenv(override=True)\n",
    "host = os.getenv(\"DB_HOST\")\n",
    "database = os.getenv(\"DB_DATABASE\")\n",
    "user = os.getenv(\"DB_USER\")\n",
    "password = os.getenv(\"DB_PASS\")\n",
    "engine_string = f\"mysql+mysqldb://{user}:{password}@{host}/esa?charset=utf8\"\n",
    "engine = create_engine(engine_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAREFUL! DELETES ALL CSV files and CSV DB entries, and resets PDFs (csvsExtracted = NULL)!\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(\"DELETE FROM esa.csvs;\")\n",
    "    print(f\"Deleted {result.rowcount} csvs from DB\")\n",
    "    result = conn.execute(\"UPDATE esa.pdfs SET csvsExtracted = NULL WHERE csvsExtracted IS NOT NULL;\")\n",
    "    print(f\"Reset {result.rowcount} PDFs from DB (csvsExtracted = NULL)\")\n",
    "csvs = list(csv_tables_folder.glob(\"*.csv\"))\n",
    "for f in csvs:\n",
    "    f.unlink()\n",
    "print(f\"Deleted {len(csvs)} CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_args_for_csv_extraction():\n",
    "    statement = text(\"SELECT * FROM esa.pdfs WHERE csvsExtracted IS NULL ORDER BY totalPages DESC;\")\n",
    "    with engine.connect() as conn:\n",
    "        df = pd.read_sql(statement, conn)\n",
    "    pdfs = df.to_dict(\"records\")\n",
    "\n",
    "    files = []\n",
    "    for pdf in pdfs:\n",
    "        pages = []\n",
    "        for page in range (1, pdf[\"totalPages\"] + 1):\n",
    "            pages.append((pdf[\"pdfId\"], page, engine_string, str(pdf_files_folder), str(csv_tables_folder)))\n",
    "        files.append(pages)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from external import extract_csv\n",
    "\n",
    "log_file = \"log.txt\"\n",
    "with Path(log_file).open(\"w\") as f:\n",
    "    pass # Clearing the log file\n",
    "\n",
    "def log_it(s):\n",
    "    with Path(log_file).open(\"a\", encoding=\"utf-8-sig\") as f:\n",
    "        f.write(s)\n",
    "    print(s)\n",
    "\n",
    "start_time = time.time()\n",
    "files = create_args_for_csv_extraction()[:]\n",
    "time_stamp = time.strftime(\"%H:%M:%S %Y-%m-%d\")\n",
    "log_it(f\"\\nItems to process: {len(files)} at {time_stamp}\\n\")\n",
    "\n",
    "for index, pages in enumerate(files):\n",
    "    pdf_id = pages[0][0]\n",
    "    time_stamp2 = time.strftime(\"%H:%M:%S %Y-%m-%d\")\n",
    "    log_it(\"\\n--------------------------------------------------------\")\n",
    "    log_it(f\"\\n{pdf_id}: {len(pages)} pages to process at {time_stamp2}\\n\\n\")\n",
    "    start_time2 = time.time()\n",
    "    with Pool() as pool:\n",
    "        results = pool.map(extract_csv, pages)\n",
    "    for result in results:\n",
    "        log_it(result)\n",
    "\n",
    "    with engine.connect() as conn:\n",
    "        statement = text(\"UPDATE esa.pdfs SET csvsExtracted = :csvsExtracted WHERE pdfId = :pdfId;\")\n",
    "        result = conn.execute(statement, {\"csvsExtracted\": 'true', \"pdfId\": pdf_id})\n",
    "    log_it(f\"\\n{pdf_id}: updated {result.rowcount} for {pdf_id} (csvsExtracted)\\n\")\n",
    "    duration2 = round(time.time() - start_time2)\n",
    "    log_it(f\"\\n{pdf_id}: done {len(pages)} pages in {duration2} seconds ({round(duration2/60, 2)} min)\\n\")\n",
    "\n",
    "duration = round(time.time() - start_time)\n",
    "log_it(f\"\\nDone {len(files)} items in {duration} seconds ({round(duration/60, 2)} min or {round(duration/3600, 2)} hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}